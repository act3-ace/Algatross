apiVersion: ray.io/v1alpha1
kind: RayCluster
metadata:
  name: raycluster-test
spec:
  rayVersion: "2.23.0"
  enableInTreeAutoscaling: true
  autoscalerOptions:
  headGroupSpec:
    serviceType: ClusterIP # Options are ClusterIP, NodePort, and LoadBalancer
    rayStartParams:
      num-cpus: "4"
      ray-debugger-external: "true"
      dashboard-host: "0.0.0.0"
    template: # Pod template
      metadata: # Pod metadata
        spec: # Pod spec
          containers:
            - name: ray-head
              image: reg.git.act3-ace.com/stalwart/ascension/mo-marl/kuberay-lite:latest
              resources:
                limits:
                  cpu: 4
                  memory: 4Gi
                requests:
                  cpu: 4
                  memory: 4Gi
              # Keep this preStop hook in each Ray container config.
              lifecycle:
                preStop:
                  exec:
                    command: ["/bin/sh", "-c", "ray stop"]
              ports: # Optional service port overrides
                - containerPort: 6379
                  name: gcs
                - containerPort: 8265
                  name: dashboard
                - containerPort: 10001
                  name: client
                - containerPort: 8000
                  name: serve
  workerGroupSpecs:
    - groupName: cpu-group
      replicas: 1
      minReplicas: 1
      maxReplicas: 10
      rayStartParams:
        num-cpus: "4"
        ray-debugger-external: "true"
      template: # Pod template
        spec:
          priorityClassName: spot
          # runtimeClassName: nvidia
          volumes:
            - name: petabyte-data
              nfs:
                path: /ifs/act3/data
                server: petabyte.act3-ace.ai
            - emptyDir:
                medium: Memory
                sizeLimit: 4Gi
              name: dshm
          containers:
            - name: actor-test
              image: reg.git.act3-ace.com/stalwart/ascension/mo-marl/kuberay-lite:latest
              resources:
                limits:
                  cpu: "4"
                  memory: 8Gi
                  nvidia.com/gpu: "0"
                requests:
                  cpu: "4"
                  memory: 8Gi
                  nvidia.com/gpu: "0"
              volumeMounts:
                - mountPath: /data/petabyte
                  name: petabyte-data
                - mountPath: /dev/shm
                  name: dshm
              # command:
              # - /bin/sh
              # - -c
              # args:
              # - echo $JOB_COMPLETION_INDEX; uv sync --frozen; python scripts/training.py
